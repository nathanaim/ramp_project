{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import date, datetime\n",
    "from astral import LocationInfo\n",
    "from astral.sun import daylight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_first_day = 'https://prevision-meteo.ch/climat/horaire/paris-montsouris/2020-09-01'\n",
    "html_first_day = requests.get(url_first_day).text\n",
    "\n",
    "soup_first_day = BeautifulSoup(html_first_day, 'html.parser')\n",
    "\n",
    "data_first_day = soup_first_day.find_all('div', {'class': 'table-responsive'})\n",
    "\n",
    "df_first_day = pd.read_html(str(data_first_day))[0]\n",
    "\n",
    "df_first_day = df_first_day.droplevel(level=0, axis=1)\n",
    "\n",
    "df_first_day['date_datetime'] = df_first_day['Heure UTC1'].map(lambda x: datetime(2020, 9, 1, int(x[:2])))\n",
    "df_first_day.drop(columns=['Heure UTC1'], inplace=True)\n",
    "\n",
    "df_all_days = df_first_day.copy()\n",
    "\n",
    "years = [2020, 2021]\n",
    "months = {2020 : [9, 10, 11, 12], 2021 : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "days = {2020 : {\n",
    "    9 : list(range(2, 31)),\n",
    "    10 : list(range(1, 32)),\n",
    "    11 : list(range(1, 31)),\n",
    "    12 : list(range(1, 32))\n",
    "},\n",
    "2021 : {\n",
    "    1 : list(range(1, 32)),\n",
    "    2 : list(range(1, 29)),\n",
    "    3 : list(range(1, 32)),\n",
    "    4 : list(range(1, 31)),\n",
    "    5 : list(range(1, 32)),\n",
    "    6 : list(range(1, 31)),\n",
    "    7 : list(range(1, 32)),\n",
    "    8 : list(range(1, 32)),\n",
    "    9 : list(range(1, 31)),\n",
    "    10 : list(range(1, 22))\n",
    "\n",
    "}}\n",
    "\n",
    "for year in years:\n",
    "    for month in months[year]:\n",
    "        for day in days[year][month]:\n",
    "            print(f'Getting data for {day}-{month}-{year}')\n",
    "\n",
    "            year_str = str(year)\n",
    "            if len(str(month)) == 1:\n",
    "                month_str = '0' + str(month)\n",
    "            else:\n",
    "                month_str = str(month)\n",
    "            if len(str(day)) == 1:\n",
    "                day_str = '0' + str(day)\n",
    "            else :\n",
    "                day_str=str(day)\n",
    "\n",
    "            if not ((year == 2020) & (month == 11) & (day in [9, 10, 11])):\n",
    "                url = f'https://prevision-meteo.ch/climat/horaire/paris-montsouris/{year_str}-{month_str}-{day_str}'\n",
    "                html = requests.get(url).text\n",
    "\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "                data = soup.find_all('div', {'class': 'table-responsive'})\n",
    "\n",
    "                df = pd.read_html(str(data))[0]\n",
    "\n",
    "                df = df.droplevel(level=0, axis=1)\n",
    "\n",
    "                df['date_datetime'] = df['Heure UTC1'].map(lambda x: datetime(year, month, day, int(x[:2])))\n",
    "                df.drop(columns=['Heure UTC1'], inplace=True)\n",
    "\n",
    "                df_all_days = pd.concat([df_all_days, df])\n",
    "                print(f'Successfully added data for {day}-{month}-{year}')\n",
    "            else : print(f'Skipped data for {day}-{month}-{year}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_days.to_csv('meteo_scraped_2.csv')\n",
    "df_reloaded = pd.read_csv('meteo_scraped_2.csv', parse_dates=['date_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_first_month = 'https://prevision-meteo.ch/climat/journalier/paris-montsouris/2020-09'\n",
    "\n",
    "html_first_month = requests.get(url_first_month).text\n",
    "\n",
    "soup_first_month = BeautifulSoup(html_first_month, 'html.parser')\n",
    "\n",
    "data_first_month = soup_first_month.find_all('div', {'class': 'table-responsive'})\n",
    "\n",
    "df_first_month = pd.read_html(str(data_first_month))[0]\n",
    "\n",
    "df_first_month = df_first_month.droplevel(level=0, axis=1)\n",
    "\n",
    "df_first_month = df_first_month[df_first_month.Date != 'Total']\n",
    "\n",
    "df_first_month['date_datetime'] = df_first_month.Date.apply(lambda x: date(2020, 9, int(x[-2:])))\n",
    "\n",
    "df_all_months = df_first_month.copy()\n",
    "\n",
    "years = [2020, 2021]\n",
    "\n",
    "months = {2020 : [10, 11, 12], 2021 : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "for year in years:\n",
    "    for month in months[year]:\n",
    "\n",
    "        print(f'Getting data for {month}-{year}')\n",
    "\n",
    "        year_str = str(year)\n",
    "        if len(str(month)) == 1:\n",
    "            month_str = '0' + str(month)\n",
    "        else:\n",
    "            month_str = str(month)\n",
    "\n",
    "        url = f'https://prevision-meteo.ch/climat/journalier/paris-montsouris/{year_str}-{month_str}'\n",
    "\n",
    "        html = requests.get(url).text\n",
    "\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        data = soup.find_all('div', {'class': 'table-responsive'})\n",
    "\n",
    "        df = pd.read_html(str(data))[0]\n",
    "        df = df.droplevel(level=0, axis=1)\n",
    "        df = df[df.Date != 'Total']\n",
    "        df['date_datetime'] = df.Date.apply(lambda x: date(year, month, int(x[-2:])))\n",
    "\n",
    "        df_all_months = pd.concat([df_all_months, df])\n",
    "\n",
    "        print (f'Successfully added data for {month}-{year}')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_months.drop(columns=['Date', 'Min1', 'Max.2', 'Moy.', 'Moy.3', 'Min'], inplace=True)\n",
    "df_all_months.columns = ['vent', 'soleil', 'pluie', 'to_drop', 'date_datetime']\n",
    "df_all_months.reset_index(inplace=True)\n",
    "df_all_months.drop(columns = ['to_drop', 'index'], inplace=True)\n",
    "df_all_months['soleil'].replace({'--' : '0h 0min'}, inplace=True)\n",
    "df_all_months['pluie'].replace({'--' : 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minutes_soleil(x):\n",
    "    hours_and_minutes = x.split()\n",
    "    hours = int(hours_and_minutes[0][:-1])\n",
    "    minutes = int(hours_and_minutes[1][:-3])\n",
    "    return 60*hours + minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_months['temps_soleil'] = df_all_months.soleil.apply(minutes_soleil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_reloaded.drop(columns = ['Unnamed: 0', 'Dir.2', 'Moy.', 'Pres.4 [hPa]', 'Nébu. [octa]'])\n",
    "df_clean['pluie_direct'] = df_clean['Préc.5 [mm]'].apply(lambda x: x.split(\"/\")[0])\n",
    "df_clean['pluie_direct'].replace({'--' : 0, 'trace' : 0.05}, inplace=True)\n",
    "df_clean['pluie_direct'] = pd.to_numeric(df_clean.pluie_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=3)\n",
    "df_clean['pluie_last_3'] = df_clean['pluie_direct'].rolling(indexer, min_periods=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['pluie_intermittente'] = df_clean['Cond.'].apply(lambda x : ('pluie' in x) & ('intermittente' in x))\n",
    "df_clean['pluie_continue'] = df_clean['Cond.'].apply(lambda x : ('pluie' in x) & ('continue' in x))\n",
    "df_clean['pluie_forte'] = df_clean['Cond.'].apply(lambda x : ('pluie' in x) & ('forte' in x))\n",
    "df_clean['pluie_faible'] = df_clean['Cond.'].apply(lambda x : ('pluie' in x) & ('faible' in x))\n",
    "df_clean['pluie_modérée'] = df_clean['Cond.'].apply(lambda x : ('pluie' in x) & ('modérée' in x))\n",
    "df_clean['neige'] = df_clean['Cond.'].apply(lambda x : ('neige' in x))\n",
    "df_clean['bruine'] = df_clean['Cond.'].apply(lambda x: 'bruine' in x)\n",
    "df_clean['brouillard'] = df_clean['Cond.'].apply(lambda x: 'brouillard' in x)\n",
    "df_clean['verglas'] = df_clean['Cond.'].apply(lambda x: 'verglaçante' in x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns=['Cond.', 'Préc.5 [mm]'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['date'] = df_clean.date_datetime.apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 and a half days were missing, so we simply replaced the missing weather data for these days by the weather data of the previous day (November 8)\n",
    "\n",
    "november_8 = df_clean[df_clean.date == date(2020, 11, 8)]\n",
    "\n",
    "november_9 = november_8.copy().reset_index()\n",
    "november_10 = november_8.copy().reset_index()\n",
    "november_11 = november_8.copy().reset_index()\n",
    "november_12 = november_8.copy().reset_index()[-10:]\n",
    "november_9['date_datetime'] = november_9.date_datetime.apply(lambda x : pd.to_datetime(str(x).replace('2020-11-08', '2020-11-09')))\n",
    "november_10['date_datetime'] = november_10.date_datetime.apply(lambda x : pd.to_datetime(str(x).replace('2020-11-08', '2020-11-10')))\n",
    "november_11['date_datetime'] = november_11.date_datetime.apply(lambda x : pd.to_datetime(str(x).replace('2020-11-08', '2020-11-11')))\n",
    "november_12['date_datetime'] = november_12.date_datetime.apply(lambda x : pd.to_datetime(str(x).replace('2020-11-08', '2020-11-12')))\n",
    "\n",
    "df_clean_full = pd.concat([df_clean, november_9, november_10, november_11, november_12])\n",
    "\n",
    "df_clean_full.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_daylight(x):\n",
    "    city=LocationInfo('Paris', timezone='Europe/Paris')\n",
    "    sun_info = daylight(city.observer, date=x.to_pydatetime().date(), tzinfo='Europe/Paris')\n",
    "    x = x.tz_localize('Europe/Paris', ambiguous=True, nonexistent='shift_forward')\n",
    "    return (x > sun_info[0]) & (x < sun_info[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_full['is_daylight'] = df_clean_full.date_datetime.map(is_daylight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_months.drop(columns = ['soleil'], inplace=True)\n",
    "df_all_months.set_index('date_datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_full['temps_soleil'] = df_clean_full.date.apply(lambda x: df_all_months.loc[x, 'temps_soleil'])\n",
    "df_clean_full['pluie_cumul_day'] = df_clean_full.date.apply(lambda x: df_all_months.loc[x, 'pluie'])\n",
    "df_clean_full['vent_max'] = df_clean_full.date.apply(lambda x: df_all_months.loc[x, 'vent'])\n",
    "df_clean_full.drop(columns=['level_0', 'index'], inplace=True)\n",
    "df_clean_full.drop(columns=['Ros.', '2m.'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_full.to_csv('meteo_scraped_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_data = pd.read_csv('external_data_reworked.csv', parse_dates=['date'])\n",
    "ext_data_index = ext_data.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_index = df_clean_full.set_index('date_datetime')\n",
    "df_clean_index.sort_index(inplace=True)\n",
    "df_clean_index['pluie_last_3'] = df_clean_index['pluie_last_3'].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_data_index.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge_asof(df_clean_index, ext_data_index, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.iloc[:, 2].replace({\"--\" : 0}, inplace=True)\n",
    "merged_data.iloc[:, 2] = merged_data.iloc[:, 2].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_hum = pd.to_numeric(merged_data[merged_data.iloc[:, 3] != \"--\"]['Hum. [%]']).mean()\n",
    "merged_data.iloc[:, 3].replace({\"--\" : mean_hum}, inplace=True)\n",
    "merged_data.iloc[:, 3] = merged_data.iloc[:, 3].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.drop(columns=['date_datetime'], inplace=True)\n",
    "merged_data.reset_index(inplace=True)\n",
    "merged_data.rename(columns={'date' : 'a', 'date_datetime' : 'b'}, inplace=True)\n",
    "\n",
    "merged_data.rename(columns={'a' : 'date_datetime', 'b' : 'date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_csv('external_data_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a487b291ff8c0d54379bc0072e6f0f6494cb31f2c49ae9cb9040e8d9fbe5a43"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('sandbox': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
